
use device: cuda
Traceback (most recent call last):
  File "main.py", line 154, in <module>
    mlp_model.to(device)
  File "/dysData/miniconda3/envs/scribblekitti/lib/python3.8/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/dysData/miniconda3/envs/scribblekitti/lib/python3.8/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/dysData/miniconda3/envs/scribblekitti/lib/python3.8/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/dysData/miniconda3/envs/scribblekitti/lib/python3.8/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
KeyboardInterrupt